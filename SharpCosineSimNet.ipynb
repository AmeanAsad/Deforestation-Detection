{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f6074e0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Amean\\anaconda3\\envs\\vision\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import time\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision\n",
    "import pandas as pd\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "from Dataset import CustomDataset\n",
    "import torchvision.transforms as transforms\n",
    "from pathlib import Path\n",
    "from AbsPool import MaxAbsPool2d\n",
    "from CosSim import SharpenedCosineSimilarity\n",
    "from metrics import F1Score\n",
    "\n",
    "batch_size = 48\n",
    "inputChannels = 3\n",
    "f1Metric = F1Score()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7bb12fb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25513\n",
      "2834\n"
     ]
    }
   ],
   "source": [
    "csvPath = Path(\"processedLabels.csv\")\n",
    "imgPath = Path(\"train-jpg\")\n",
    "\n",
    "data = pd.read_csv(csvPath)\n",
    "data = data.sample(frac = 1)\n",
    "data = data.reset_index(drop=True)\n",
    "data.head()\n",
    "\n",
    "datasetLen = len(data)\n",
    "validationSetLen =  int(datasetLen*0.1)\n",
    "validationSet = data[:validationSetLen]\n",
    "\n",
    "trainSet = data[validationSetLen:]\n",
    "\n",
    "print(len(trainSet))\n",
    "print(len(validationSet))\n",
    "trainSet = trainSet.reset_index(drop=True)\n",
    "\n",
    "\n",
    "transformations = transforms.Compose([transforms.ToTensor()])\n",
    "composed = transforms.Compose([\n",
    "    transforms.RandomCrop(256, padding=4),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "dataTrain = CustomDataset(trainSet, imgPath, transform=transformations)\n",
    "dataTest = CustomDataset(validationSet, imgPath, transform=transformations)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "890dbd11",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Helper Functions\n",
    "def get_default_device():\n",
    "    \"\"\"Pick GPU if available, else CPU\"\"\"\n",
    "    if torch.cuda.is_available():\n",
    "        return torch.device('cuda')\n",
    "    else:\n",
    "        return torch.device('cpu')\n",
    "\n",
    "\n",
    "def to_device(data, device):\n",
    "    \"\"\"Move tensor(s) to chosen device\"\"\"\n",
    "    if isinstance(data, (list, tuple)):\n",
    "        return [to_device(x, device) for x in data]\n",
    "    return data.to(device, non_blocking=True)\n",
    "\n",
    "\n",
    "class DeviceDataLoader():\n",
    "    \"\"\"Wrap a dataloader to move data to a device\"\"\"\n",
    "\n",
    "    def __init__(self, dl, device):\n",
    "        self.dl = dl\n",
    "        self.device = device\n",
    "\n",
    "    def __iter__(self):\n",
    "        \"\"\"Yield a batch of data after moving it to device\"\"\"\n",
    "        for b in self.dl:\n",
    "            yield to_device(b, self.device)\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"Number of batches\"\"\"\n",
    "        return len(self.dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "16c16dd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(outputs, labels):\n",
    "    _, preds = torch.max(outputs, dim=1)\n",
    "    return torch.tensor(torch.sum(preds == labels).item() / len(preds))\n",
    "\n",
    "def F1Compute(outputs, labels):\n",
    "    _, preds = torch.max(outputs, dim=1)\n",
    "    return f1Metric(labels.float(), preds.float())\n",
    "\n",
    "    \n",
    "\n",
    "class BaseModule(nn.Module):\n",
    "    def training_step(self, batch):\n",
    "        images, labels = batch \n",
    "        out = self(images)\n",
    "        loss = F.cross_entropy(out.float(), labels) \n",
    "        return loss\n",
    "    \n",
    "    def validation_step(self, batch):\n",
    "        images, labels = batch \n",
    "        out = self(images)   \n",
    "        loss = F.cross_entropy(out, labels)   \n",
    "        acc = accuracy(out, labels)\n",
    "        f1score = F1Compute(out,labels)\n",
    "        return {'val_loss': loss.detach(), 'val_acc': acc, \"f1score\": f1score}\n",
    "    \n",
    "    def train_val_step(self, batch):\n",
    "        images, labels = batch \n",
    "        out = self(images)   \n",
    "        labels=labels.to(torch.int64)\n",
    "\n",
    "        loss = F.cross_entropy(out, labels)   \n",
    "        acc = accuracy(out, labels)        \n",
    "        return {'train_loss': loss.detach(), 'train_acc': acc}\n",
    "        \n",
    "    def validation_epoch_end(self, outputs):\n",
    "        batch_losses = [x['val_loss'] for x in outputs]\n",
    "        epoch_loss = torch.stack(batch_losses).mean()\n",
    "        batch_f1s = [x['f1score'] for x in outputs]\n",
    "        epoch_f1 = torch.stack(batch_f1s).mean() \n",
    "        batch_accs = [x['val_acc'] for x in outputs]\n",
    "        epoch_acc = torch.stack(batch_accs).mean()      \n",
    "        return {'val_loss': epoch_loss.item(), 'val_acc': epoch_acc.item(), \"f1\": epoch_f1.item()}\n",
    "       \n",
    "    def epoch_end(self, epoch, result):\n",
    "        print(\"Epoch {}, Validation Loss: {:.4f}, Validation Accuracy: {:.4f}, F1: {:.4f}\"\n",
    "              .format(epoch + 1, result['val_loss'], result['val_acc'], result[\"f1\"]))\n",
    "        \n",
    "\n",
    "@torch.no_grad()\n",
    "def evaluate(model, val_loader):\n",
    "    model.eval()\n",
    "    outputs = [model.validation_step(batch) for batch in val_loader]\n",
    "    return model.validation_epoch_end(outputs)\n",
    "\n",
    "def fit(epochs, lr, model, train_loader, val_loader, opt_func=torch.optim.SGD):\n",
    "    history = []\n",
    "\n",
    "    if opt_func == torch.optim.SGD:\n",
    "        optimizer = opt_func(model.parameters(), lr, momentum=0.9)\n",
    "    else:\n",
    "        optimizer = opt_func(model.parameters(), lr)\n",
    "        \n",
    "    scheduler = StepLR(optimizer, step_size=10, gamma=0.3)\n",
    "    for epoch in range(epochs):\n",
    "        # Training Phase \n",
    "        model.train()\n",
    "        train_losses = []\n",
    "        for batch in train_loader:\n",
    "            loss = model.training_step(batch)\n",
    "            train_losses.append(loss)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "        scheduler.step()\n",
    "\n",
    "        # Validation phase\n",
    "        result = evaluate(model, val_loader)\n",
    "        result['train_loss'] = torch.stack(train_losses).mean().item()\n",
    "        model.epoch_end(epoch, result)\n",
    "        history.append(result)\n",
    "    return history\n",
    "\n",
    "\n",
    "def plotResults(history,name):\n",
    "    losses = [entry['val_loss'] for entry in history]\n",
    "    accuracy = [entry[\"val_acc\"] for entry in history]\n",
    "    train_loss = [entry[\"train_loss\"] for entry in history]\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(10,5))\n",
    "    fig.suptitle('Model Results')\n",
    "\n",
    "    ax1.plot(losses, '-o', label=\"Validation Loss\")\n",
    "    ax1.plot(train_loss, \"-s\", label=\"Training Loss\")\n",
    "    ax1.legend()\n",
    "    ax1.set_ylim([0,5])\n",
    "    ax1.set(xlabel = 'Epoch', ylabel=\"Loss\")\n",
    "\n",
    "    \n",
    "    ax2.set(xlabel = 'Epoch', ylabel=\"Values\")\n",
    "    ax2.plot(accuracy, \"-r\")\n",
    "\n",
    "    # plt.legend()\n",
    "    ax1.set_title('Loss vs. Number of Epochs');\n",
    "    ax2.set_title(\"Accuracy on Validation Set\");\n",
    "    plt.savefig(\"{}-results.png\".format(name))\n",
    "    plt.show()\n",
    "\n",
    "    \n",
    "histories = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "43d5197f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = get_default_device()\n",
    "\n",
    "\n",
    "train = DataLoader(dataTrain,\n",
    "                          batch_size=batch_size,\n",
    "                          shuffle=True,\n",
    "                          num_workers=0, # 1 for CUDA\n",
    "                          pin_memory=True, # CUDA only\n",
    "                          drop_last=True,\n",
    "                  )\n",
    "\n",
    "test = DataLoader(dataTest,\n",
    "                          batch_size=batch_size,\n",
    "                          num_workers=0, # 1 for CUDA\n",
    "                          pin_memory=True, # CUDA only\n",
    "                          drop_last=True\n",
    "                         )\n",
    "\n",
    "train_loader = DeviceDataLoader(train, device)\n",
    "val_loader = DeviceDataLoader(test, device)\n",
    "\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bef87fe8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Amean\\anaconda3\\envs\\vision\\lib\\site-packages\\torch\\nn\\functional.py:780: UserWarning: Note that order of the arguments: ceil_mode and return_indices will changeto match the args list in nn.MaxPool2d in a future release.\n",
      "  warnings.warn(\"Note that order of the arguments: ceil_mode and return_indices will change\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Validation Loss: 0.5094, Validation Accuracy: 0.7528, F1: 0.8011\n",
      "Epoch 2, Validation Loss: 0.4917, Validation Accuracy: 0.7715, F1: 0.8346\n",
      "Epoch 3, Validation Loss: 0.4783, Validation Accuracy: 0.8001, F1: 0.8419\n",
      "Epoch 4, Validation Loss: 0.4757, Validation Accuracy: 0.7793, F1: 0.8413\n",
      "Epoch 5, Validation Loss: 0.4072, Validation Accuracy: 0.8319, F1: 0.8702\n",
      "Epoch 6, Validation Loss: 0.3591, Validation Accuracy: 0.8531, F1: 0.8865\n",
      "Epoch 7, Validation Loss: 0.3567, Validation Accuracy: 0.8598, F1: 0.8891\n",
      "Epoch 8, Validation Loss: 0.3621, Validation Accuracy: 0.8482, F1: 0.8859\n",
      "Epoch 9, Validation Loss: 0.3239, Validation Accuracy: 0.8662, F1: 0.8924\n",
      "Epoch 10, Validation Loss: 0.3244, Validation Accuracy: 0.8630, F1: 0.8885\n",
      "Epoch 11, Validation Loss: 0.3096, Validation Accuracy: 0.8729, F1: 0.9001\n",
      "Epoch 12, Validation Loss: 0.3202, Validation Accuracy: 0.8630, F1: 0.8948\n",
      "Epoch 13, Validation Loss: 0.3062, Validation Accuracy: 0.8708, F1: 0.8982\n",
      "Epoch 14, Validation Loss: 0.3063, Validation Accuracy: 0.8718, F1: 0.8993\n",
      "Epoch 15, Validation Loss: 0.3035, Validation Accuracy: 0.8754, F1: 0.9019\n",
      "Epoch 16, Validation Loss: 0.2999, Validation Accuracy: 0.8824, F1: 0.9068\n",
      "Epoch 17, Validation Loss: 0.3051, Validation Accuracy: 0.8711, F1: 0.8998\n",
      "Epoch 18, Validation Loss: 0.2944, Validation Accuracy: 0.8828, F1: 0.9079\n",
      "Epoch 19, Validation Loss: 0.2939, Validation Accuracy: 0.8817, F1: 0.9061\n",
      "Epoch 20, Validation Loss: 0.3143, Validation Accuracy: 0.8676, F1: 0.8997\n"
     ]
    }
   ],
   "source": [
    "\n",
    "class CosSimNet(BaseModule):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.layer1 = SharpenedCosineSimilarity(\n",
    "            in_channels=inputChannels,\n",
    "            out_channels=16,\n",
    "            kernel_size=5,\n",
    "            padding=0)\n",
    "        self.poolLayer1 = MaxAbsPool2d(kernel_size=2, stride=2, ceil_mode=True)\n",
    "\n",
    "        self.layer2 = SharpenedCosineSimilarity(\n",
    "            in_channels=16,\n",
    "            out_channels=16,\n",
    "            kernel_size=5,\n",
    "            padding=1)\n",
    "        self.poolLayer2 = MaxAbsPool2d(kernel_size=2, stride=2, ceil_mode=True)\n",
    "\n",
    "        self.layer3 = SharpenedCosineSimilarity(\n",
    "            in_channels=16,\n",
    "            out_channels=16,\n",
    "            kernel_size=5,\n",
    "            padding=1)\n",
    "        self.poolLayer3 = MaxAbsPool2d(kernel_size=4, stride=4, ceil_mode=True)\n",
    "        self.out = nn.Linear(in_features=3600, out_features=2)\n",
    "\n",
    "    def paramCount(self):\n",
    "        n = 0\n",
    "        for layer in [self.layer1, self.layer2, self.layer3]:\n",
    "            n += (\n",
    "                np.prod(layer.weight.shape) +\n",
    "                np.prod(layer.p.shape) +\n",
    "                np.prod(layer.q.shape))\n",
    "        n += np.prod(self.out.weight.shape)\n",
    "        return n\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.layer1(x)\n",
    "        x = self.poolLayer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.poolLayer2(x)\n",
    "\n",
    "        x = self.layer3(x)\n",
    "        x = self.poolLayer3(x)\n",
    "       \n",
    "        x = x.reshape(batch_size, -1)  # basically nn.Flatten\n",
    "        x = self.out(x)\n",
    "        return x\n",
    "\n",
    "name = \"CosSim\"\n",
    "model = to_device(CosSimNet(), device)\n",
    "history = [evaluate(model, val_loader)]\n",
    "num_epochs = 20\n",
    "opt_func = torch.optim.Adam\n",
    "lr = 5e-4\n",
    "history= fit(num_epochs, lr, model, train_loader, val_loader)\n",
    "histories[name] = history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0b394732",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Validation Loss: 0.5352, Validation Accuracy: 0.7281, F1: 0.7658\n",
      "Epoch 2, Validation Loss: 0.4907, Validation Accuracy: 0.7814, F1: 0.8322\n",
      "Epoch 3, Validation Loss: 0.4797, Validation Accuracy: 0.7871, F1: 0.8388\n",
      "Epoch 4, Validation Loss: 0.4963, Validation Accuracy: 0.7680, F1: 0.8343\n",
      "Epoch 5, Validation Loss: 0.4252, Validation Accuracy: 0.8323, F1: 0.8704\n",
      "Epoch 6, Validation Loss: 0.3966, Validation Accuracy: 0.8294, F1: 0.8719\n",
      "Epoch 7, Validation Loss: 0.3543, Validation Accuracy: 0.8545, F1: 0.8829\n",
      "Epoch 8, Validation Loss: 0.3218, Validation Accuracy: 0.8623, F1: 0.8910\n",
      "Epoch 9, Validation Loss: 0.3227, Validation Accuracy: 0.8612, F1: 0.8920\n",
      "Epoch 10, Validation Loss: 0.3143, Validation Accuracy: 0.8686, F1: 0.8940\n",
      "Epoch 11, Validation Loss: 0.3007, Validation Accuracy: 0.8694, F1: 0.8961\n",
      "Epoch 12, Validation Loss: 0.3060, Validation Accuracy: 0.8708, F1: 0.8988\n",
      "Epoch 13, Validation Loss: 0.3015, Validation Accuracy: 0.8711, F1: 0.8986\n",
      "Epoch 14, Validation Loss: 0.3083, Validation Accuracy: 0.8725, F1: 0.9003\n",
      "Epoch 15, Validation Loss: 0.3001, Validation Accuracy: 0.8743, F1: 0.8981\n",
      "Epoch 16, Validation Loss: 0.2957, Validation Accuracy: 0.8739, F1: 0.9006\n",
      "Epoch 17, Validation Loss: 0.2952, Validation Accuracy: 0.8736, F1: 0.9007\n",
      "Epoch 18, Validation Loss: 0.2966, Validation Accuracy: 0.8778, F1: 0.9049\n",
      "Epoch 19, Validation Loss: 0.3007, Validation Accuracy: 0.8725, F1: 0.8989\n",
      "Epoch 20, Validation Loss: 0.2938, Validation Accuracy: 0.8785, F1: 0.9035\n"
     ]
    }
   ],
   "source": [
    "\n",
    "class CosSimNet2(BaseModule):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.layer1 = SharpenedCosineSimilarity(\n",
    "            in_channels=inputChannels,\n",
    "            out_channels=16,\n",
    "            kernel_size=5,\n",
    "            padding=0)\n",
    "        self.poolLayer1 = MaxAbsPool2d(kernel_size=2, stride=2, ceil_mode=True)\n",
    "\n",
    "        self.layer2 = SharpenedCosineSimilarity(\n",
    "            in_channels=16,\n",
    "            out_channels=16,\n",
    "            kernel_size=5,\n",
    "            padding=1)\n",
    "        self.poolLayer2 = MaxAbsPool2d(kernel_size=2, stride=2, ceil_mode=True)\n",
    "\n",
    "        self.layer3 = SharpenedCosineSimilarity(\n",
    "            in_channels=16,\n",
    "            out_channels=16,\n",
    "            kernel_size=5,\n",
    "            padding=1)\n",
    "        self.poolLayer3 = MaxAbsPool2d(kernel_size=2, stride=2, ceil_mode=True)\n",
    "        self.layer4 = SharpenedCosineSimilarity(\n",
    "            in_channels=16,\n",
    "            out_channels=16,\n",
    "            kernel_size=5,\n",
    "            padding=1)\n",
    "        self.poolLayer4 = MaxAbsPool2d(kernel_size=4, stride=4, ceil_mode=True)\n",
    "        self.out = nn.Linear(in_features=784, out_features=2)\n",
    "\n",
    "    def paramCount(self):\n",
    "        n = 0\n",
    "        for layer in [self.layer1, self.layer2, self.layer3, self.layer4]:\n",
    "            n += (\n",
    "                np.prod(layer.weight.shape) +\n",
    "                np.prod(layer.p.shape) +\n",
    "                np.prod(layer.q.shape))\n",
    "        n += np.prod(self.out.weight.shape)\n",
    "        return n\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.layer1(x)\n",
    "        x = self.poolLayer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.poolLayer2(x)\n",
    "\n",
    "        x = self.layer3(x)\n",
    "        x = self.poolLayer3(x)\n",
    "        x = self.layer4(x)\n",
    "        x = self.poolLayer4(x)\n",
    "        x = x.reshape(batch_size, -1)  # basically nn.Flatten\n",
    "        x = self.out(x)\n",
    "        return x\n",
    "\n",
    "name = \"CosSim2\"\n",
    "model = to_device(CosSimNet2(), device)\n",
    "history = [evaluate(model, val_loader)]\n",
    "num_epochs = 15\n",
    "opt_func = torch.optim.Adam\n",
    "lr = 5e-4\n",
    "history += fit(num_epochs, lr, model, train_loader, val_loader)\n",
    "histories[name] = history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f48ba81b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Amean\\anaconda3\\envs\\vision\\lib\\site-packages\\torch\\nn\\functional.py:780: UserWarning: Note that order of the arguments: ceil_mode and return_indices will changeto match the args list in nn.MaxPool2d in a future release.\n",
      "  warnings.warn(\"Note that order of the arguments: ceil_mode and return_indices will change\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Validation Loss: 0.5061, Validation Accuracy: 0.7549, F1: 0.8255\n",
      "Epoch 2, Validation Loss: 0.4829, Validation Accuracy: 0.7694, F1: 0.8330\n",
      "Epoch 3, Validation Loss: 0.4796, Validation Accuracy: 0.7726, F1: 0.8359\n",
      "Epoch 4, Validation Loss: 0.4510, Validation Accuracy: 0.7956, F1: 0.8446\n",
      "Epoch 5, Validation Loss: 0.4343, Validation Accuracy: 0.8072, F1: 0.8546\n",
      "Epoch 6, Validation Loss: 0.3848, Validation Accuracy: 0.8340, F1: 0.8720\n",
      "Epoch 7, Validation Loss: 0.3690, Validation Accuracy: 0.8485, F1: 0.8793\n",
      "Epoch 8, Validation Loss: 0.3733, Validation Accuracy: 0.8411, F1: 0.8788\n",
      "Epoch 9, Validation Loss: 0.3644, Validation Accuracy: 0.8559, F1: 0.8871\n",
      "Epoch 10, Validation Loss: 0.3200, Validation Accuracy: 0.8796, F1: 0.9016\n",
      "Epoch 11, Validation Loss: 0.3049, Validation Accuracy: 0.8754, F1: 0.8993\n",
      "Epoch 12, Validation Loss: 0.3071, Validation Accuracy: 0.8746, F1: 0.8995\n",
      "Epoch 13, Validation Loss: 0.3092, Validation Accuracy: 0.8803, F1: 0.9011\n",
      "Epoch 14, Validation Loss: 0.3026, Validation Accuracy: 0.8778, F1: 0.9011\n",
      "Epoch 15, Validation Loss: 0.3007, Validation Accuracy: 0.8761, F1: 0.9002\n",
      "Epoch 16, Validation Loss: 0.3023, Validation Accuracy: 0.8743, F1: 0.8994\n",
      "Epoch 17, Validation Loss: 0.3148, Validation Accuracy: 0.8824, F1: 0.9052\n",
      "Epoch 18, Validation Loss: 0.2981, Validation Accuracy: 0.8863, F1: 0.9074\n",
      "Epoch 19, Validation Loss: 0.2987, Validation Accuracy: 0.8750, F1: 0.8999\n",
      "Epoch 20, Validation Loss: 0.3115, Validation Accuracy: 0.8701, F1: 0.8978\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "class CosSimNet3(BaseModule):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.layer1 = SharpenedCosineSimilarity(\n",
    "            in_channels=inputChannels,\n",
    "            out_channels=16,\n",
    "            kernel_size=5,\n",
    "            padding=0)\n",
    "        self.poolLayer1 = MaxAbsPool2d(kernel_size=2, stride=2, ceil_mode=True)\n",
    "\n",
    "        self.layer2 = SharpenedCosineSimilarity(\n",
    "            in_channels=16,\n",
    "            out_channels=32,\n",
    "            kernel_size=5,\n",
    "            padding=1)\n",
    "        self.poolLayer2 = MaxAbsPool2d(kernel_size=2, stride=2, ceil_mode=True)\n",
    "\n",
    "        self.layer3 = SharpenedCosineSimilarity(\n",
    "            in_channels=32,\n",
    "            out_channels=32,\n",
    "            kernel_size=5,\n",
    "            padding=1)\n",
    "        self.poolLayer3 = MaxAbsPool2d(kernel_size=2, stride=2, ceil_mode=True)\n",
    "        self.layer4 = SharpenedCosineSimilarity(\n",
    "            in_channels=32,\n",
    "            out_channels=32,\n",
    "            kernel_size=5,\n",
    "            padding=1)\n",
    "        self.poolLayer4 = MaxAbsPool2d(kernel_size=4, stride=4, ceil_mode=True)\n",
    "        self.out = nn.Linear(in_features=28800, out_features=2)\n",
    "\n",
    "    def paramCount(self):\n",
    "        n = 0\n",
    "        for layer in [self.layer1, self.layer2, self.layer3, self.layer4]:\n",
    "            n += (\n",
    "                np.prod(layer.weight.shape) +\n",
    "                np.prod(layer.p.shape) +\n",
    "                np.prod(layer.q.shape))\n",
    "        n += np.prod(self.out.weight.shape)\n",
    "        return n\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.layer1(x)\n",
    "        x = self.poolLayer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.poolLayer2(x)\n",
    "\n",
    "        x = self.layer3(x)\n",
    "        x = self.poolLayer3(x)\n",
    "        x = x.reshape(batch_size, -1)  # basically nn.Flatten\n",
    "        x = self.out(x)\n",
    "        return x\n",
    "\n",
    "name =\"CosSim3\"\n",
    "model = to_device(CosSimNet3(), device)\n",
    "history = [evaluate(model, val_loader)]\n",
    "num_epochs = 20\n",
    "opt_func = torch.optim.Adam\n",
    "lr = 7e-4\n",
    "history += fit(num_epochs, lr, model, train_loader, val_loader)\n",
    "histories[name] = history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19a037da",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "\n",
    "with open('cosNets2.json', 'w') as outfile:\n",
    "    json.dump(histories, outfile)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
