{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f6074e0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Amean\\anaconda3\\envs\\vision\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import time\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision\n",
    "import pandas as pd\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "from Dataset import CustomDataset\n",
    "import torchvision.transforms as transforms\n",
    "from pathlib import Path\n",
    "from metrics import F1Score\n",
    "\n",
    "batch_size = 48\n",
    "f1Metric = F1Score()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7bb12fb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25513\n",
      "2834\n"
     ]
    }
   ],
   "source": [
    "csvPath = Path(\"processedLabels.csv\")\n",
    "imgPath = Path(\"train-jpg\")\n",
    "\n",
    "data = pd.read_csv(csvPath)\n",
    "data = data.sample(frac = 1)\n",
    "data = data.reset_index(drop=True)\n",
    "data.head()\n",
    "\n",
    "datasetLen = len(data)\n",
    "validationSetLen =  int(datasetLen*0.1)\n",
    "validationSet = data[:validationSetLen]\n",
    "\n",
    "trainSet = data[validationSetLen:]\n",
    "\n",
    "print(len(trainSet))\n",
    "print(len(validationSet))\n",
    "trainSet = trainSet.reset_index(drop=True)\n",
    "\n",
    "\n",
    "transformations = transforms.Compose([transforms.ToTensor()])\n",
    "composed = transforms.Compose([\n",
    "    transforms.RandomCrop(256, padding=4),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "dataTrain = CustomDataset(trainSet, imgPath, transform=composed)\n",
    "dataTest = CustomDataset(validationSet, imgPath, transform=composed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "890dbd11",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Helper Functions\n",
    "def get_default_device():\n",
    "    \"\"\"Pick GPU if available, else CPU\"\"\"\n",
    "    if torch.cuda.is_available():\n",
    "        return torch.device('cuda')\n",
    "    else:\n",
    "        return torch.device('cpu')\n",
    "\n",
    "\n",
    "def to_device(data, device):\n",
    "    \"\"\"Move tensor(s) to chosen device\"\"\"\n",
    "    if isinstance(data, (list, tuple)):\n",
    "        return [to_device(x, device) for x in data]\n",
    "    return data.to(device, non_blocking=True)\n",
    "\n",
    "\n",
    "class DeviceDataLoader():\n",
    "    \"\"\"Wrap a dataloader to move data to a device\"\"\"\n",
    "\n",
    "    def __init__(self, dl, device):\n",
    "        self.dl = dl\n",
    "        self.device = device\n",
    "\n",
    "    def __iter__(self):\n",
    "        \"\"\"Yield a batch of data after moving it to device\"\"\"\n",
    "        for b in self.dl:\n",
    "            yield to_device(b, self.device)\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"Number of batches\"\"\"\n",
    "        return len(self.dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "16c16dd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(outputs, labels):\n",
    "    _, preds = torch.max(outputs, dim=1)\n",
    "    return torch.tensor(torch.sum(preds == labels).item() / len(preds))\n",
    "\n",
    "def F1Compute(outputs, labels):\n",
    "    _, preds = torch.max(outputs, dim=1)\n",
    "    return f1Metric(labels.float(), preds.float())\n",
    "\n",
    "    \n",
    "\n",
    "class BaseModule(nn.Module):\n",
    "    def training_step(self, batch):\n",
    "        images, labels = batch \n",
    "        out = self(images)\n",
    "        loss = F.cross_entropy(out.float(), labels) \n",
    "        return loss\n",
    "    \n",
    "    def validation_step(self, batch):\n",
    "        images, labels = batch \n",
    "        out = self(images)   \n",
    "        loss = F.cross_entropy(out, labels)   \n",
    "        acc = accuracy(out, labels)\n",
    "        f1score = F1Compute(out,labels)\n",
    "        return {'val_loss': loss.detach(), 'val_acc': acc, \"f1score\": f1score}\n",
    "    \n",
    "    def train_val_step(self, batch):\n",
    "        images, labels = batch \n",
    "        out = self(images)   \n",
    "        labels=labels.to(torch.int64)\n",
    "\n",
    "        loss = F.cross_entropy(out, labels)   \n",
    "        acc = accuracy(out, labels)        \n",
    "        return {'train_loss': loss.detach(), 'train_acc': acc}\n",
    "        \n",
    "    def validation_epoch_end(self, outputs):\n",
    "        batch_losses = [x['val_loss'] for x in outputs]\n",
    "        epoch_loss = torch.stack(batch_losses).mean()\n",
    "        batch_f1s = [x['f1score'] for x in outputs]\n",
    "        epoch_f1 = torch.stack(batch_f1s).mean() \n",
    "        batch_accs = [x['val_acc'] for x in outputs]\n",
    "        epoch_acc = torch.stack(batch_accs).mean()      \n",
    "        return {'val_loss': epoch_loss.item(), 'val_acc': epoch_acc.item(), \"f1\": epoch_f1.item()}\n",
    "       \n",
    "    def epoch_end(self, epoch, result):\n",
    "        print(\"Epoch {}, Validation Loss: {:.4f}, Validation Accuracy: {:.4f}, F1: {:.4f}\"\n",
    "              .format(epoch + 1, result['val_loss'], result['val_acc'], result[\"f1\"]))\n",
    "        \n",
    "\n",
    "@torch.no_grad()\n",
    "def evaluate(model, val_loader):\n",
    "    model.eval()\n",
    "    outputs = [model.validation_step(batch) for batch in val_loader]\n",
    "    return model.validation_epoch_end(outputs)\n",
    "\n",
    "def fit(epochs, lr, model, train_loader, val_loader, opt_func=torch.optim.SGD):\n",
    "    history = []\n",
    "\n",
    "    if opt_func == torch.optim.SGD:\n",
    "        optimizer = opt_func(model.parameters(), lr, momentum=0.9)\n",
    "    else:\n",
    "        optimizer = opt_func(model.parameters(), lr)\n",
    "        \n",
    "    scheduler = StepLR(optimizer, step_size=10, gamma=0.2)\n",
    "    for epoch in range(epochs):\n",
    "        # Training Phase \n",
    "        model.train()\n",
    "        train_losses = []\n",
    "        for batch in train_loader:\n",
    "            loss = model.training_step(batch)\n",
    "            train_losses.append(loss)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "        scheduler.step()\n",
    "\n",
    "        # Validation phase\n",
    "        result = evaluate(model, val_loader)\n",
    "        result['train_loss'] = torch.stack(train_losses).mean().item()\n",
    "        model.epoch_end(epoch, result)\n",
    "        history.append(result)\n",
    "    return history\n",
    "\n",
    "\n",
    "def plotResults(history,name):\n",
    "    losses = [entry['val_loss'] for entry in history]\n",
    "    accuracy = [entry[\"val_acc\"] for entry in history]\n",
    "    train_loss = [entry[\"train_loss\"] for entry in history]\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(10,5))\n",
    "    fig.suptitle('Model Results')\n",
    "\n",
    "    ax1.plot(losses, '-o', label=\"Validation Loss\")\n",
    "    ax1.plot(train_loss, \"-s\", label=\"Training Loss\")\n",
    "    ax1.legend()\n",
    "    ax1.set_ylim([0,5])\n",
    "    ax1.set(xlabel = 'Epoch', ylabel=\"Loss\")\n",
    "\n",
    "    \n",
    "    ax2.set(xlabel = 'Epoch', ylabel=\"Values\")\n",
    "    ax2.plot(accuracy, \"-r\")\n",
    "\n",
    "    # plt.legend()\n",
    "    ax1.set_title('Loss vs. Number of Epochs');\n",
    "    ax2.set_title(\"Accuracy on Validation Set\");\n",
    "    plt.savefig(\"{}-results.png\".format(name))\n",
    "    plt.show()\n",
    "\n",
    "    \n",
    "histories = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "43d5197f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = get_default_device()\n",
    "\n",
    "\n",
    "train = DataLoader(dataTrain,\n",
    "                          batch_size=batch_size,\n",
    "                          shuffle=True,\n",
    "                          num_workers=0, # 1 for CUDA\n",
    "                          pin_memory=True, # CUDA only\n",
    "                          drop_last=True,\n",
    "                  )\n",
    "\n",
    "test = DataLoader(dataTest,\n",
    "                          batch_size=batch_size,\n",
    "                          num_workers=0, # 1 for CUDA\n",
    "                          pin_memory=True, # CUDA only\n",
    "                          drop_last=True\n",
    "                         )\n",
    "\n",
    "train_loader = DeviceDataLoader(train, device)\n",
    "val_loader = DeviceDataLoader(test, device)\n",
    "\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bef87fe8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Validation Loss: 0.3695, Validation Accuracy: 0.8312, F1: 0.8694\n",
      "Epoch 2, Validation Loss: 0.3043, Validation Accuracy: 0.8736, F1: 0.8952\n",
      "Epoch 3, Validation Loss: 0.2925, Validation Accuracy: 0.8778, F1: 0.8993\n",
      "Epoch 4, Validation Loss: 0.2811, Validation Accuracy: 0.8884, F1: 0.9097\n",
      "Epoch 5, Validation Loss: 0.2647, Validation Accuracy: 0.8927, F1: 0.9123\n",
      "Epoch 6, Validation Loss: 0.2918, Validation Accuracy: 0.8799, F1: 0.9052\n",
      "Epoch 7, Validation Loss: 0.2632, Validation Accuracy: 0.8912, F1: 0.9108\n",
      "Epoch 8, Validation Loss: 0.2714, Validation Accuracy: 0.8874, F1: 0.9062\n",
      "Epoch 9, Validation Loss: 0.2492, Validation Accuracy: 0.8997, F1: 0.9175\n",
      "Epoch 10, Validation Loss: 0.2460, Validation Accuracy: 0.9008, F1: 0.9189\n",
      "Epoch 11, Validation Loss: 0.2270, Validation Accuracy: 0.9068, F1: 0.9237\n",
      "Epoch 12, Validation Loss: 0.2306, Validation Accuracy: 0.9061, F1: 0.9234\n",
      "Epoch 13, Validation Loss: 0.2294, Validation Accuracy: 0.9103, F1: 0.9278\n",
      "Epoch 14, Validation Loss: 0.2342, Validation Accuracy: 0.9043, F1: 0.9226\n",
      "Epoch 15, Validation Loss: 0.2356, Validation Accuracy: 0.9085, F1: 0.9263\n",
      "Epoch 16, Validation Loss: 0.2322, Validation Accuracy: 0.9089, F1: 0.9265\n",
      "Epoch 17, Validation Loss: 0.2436, Validation Accuracy: 0.9075, F1: 0.9231\n",
      "Epoch 18, Validation Loss: 0.2457, Validation Accuracy: 0.9011, F1: 0.9192\n",
      "Epoch 19, Validation Loss: 0.2323, Validation Accuracy: 0.9100, F1: 0.9263\n",
      "Epoch 20, Validation Loss: 0.2338, Validation Accuracy: 0.9114, F1: 0.9273\n"
     ]
    }
   ],
   "source": [
    "class Net(BaseModule):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Conv2d(3, 32, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.Conv2d(32, 32, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            \n",
    "            nn.MaxPool2d(2, 2), # output: 64 x 16 x 16\n",
    "\n",
    "            nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2), # output: 128 x 8 x 8\n",
    "    \n",
    "            nn.Conv2d(64, 64, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2), # output: 256 x 4 x 4\n",
    "    \n",
    "            nn.Conv2d(64, 64, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2), # output: 256 x 4 x 4\n",
    "            nn.Flatten(), \n",
    "            nn.Linear(16384 , 256),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, 2),\n",
    "          \n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "name = \"ConvNet1\"\n",
    "model = to_device(Net(), device)\n",
    "# model = model.cuda()\n",
    "history = [evaluate(model, val_loader)]\n",
    "num_epochs = 20\n",
    "opt_func = torch.optim.Adam\n",
    "lr = 6e-4\n",
    "history += fit(num_epochs, lr, model, train_loader, val_loader)\n",
    "histories[name] = history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "50397193",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Validation Loss: 0.3513, Validation Accuracy: 0.8535, F1: 0.8850\n",
      "Epoch 2, Validation Loss: 0.2982, Validation Accuracy: 0.8757, F1: 0.8977\n",
      "Epoch 3, Validation Loss: 0.2952, Validation Accuracy: 0.8796, F1: 0.9031\n",
      "Epoch 4, Validation Loss: 0.2860, Validation Accuracy: 0.8799, F1: 0.9022\n",
      "Epoch 5, Validation Loss: 0.2715, Validation Accuracy: 0.8870, F1: 0.9078\n",
      "Epoch 6, Validation Loss: 0.2944, Validation Accuracy: 0.8845, F1: 0.9079\n",
      "Epoch 7, Validation Loss: 0.2815, Validation Accuracy: 0.8842, F1: 0.9075\n",
      "Epoch 8, Validation Loss: 0.2690, Validation Accuracy: 0.8877, F1: 0.9058\n",
      "Epoch 9, Validation Loss: 0.2991, Validation Accuracy: 0.8796, F1: 0.9005\n",
      "Epoch 10, Validation Loss: 0.2741, Validation Accuracy: 0.8877, F1: 0.9083\n",
      "Epoch 11, Validation Loss: 0.2521, Validation Accuracy: 0.9025, F1: 0.9212\n",
      "Epoch 12, Validation Loss: 0.2487, Validation Accuracy: 0.9011, F1: 0.9189\n",
      "Epoch 13, Validation Loss: 0.2463, Validation Accuracy: 0.9004, F1: 0.9183\n",
      "Epoch 14, Validation Loss: 0.2478, Validation Accuracy: 0.9043, F1: 0.9213\n",
      "Epoch 15, Validation Loss: 0.2458, Validation Accuracy: 0.9057, F1: 0.9232\n"
     ]
    }
   ],
   "source": [
    "class Net2(BaseModule):\n",
    "    def __init__(self):\n",
    "        super(Net2, self).__init__()\n",
    "\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Conv2d(3, 32, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(),\n",
    "\n",
    "            nn.MaxPool2d(2, 2),\n",
    "\n",
    "            nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1), \n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "\n",
    "\n",
    "            nn.Conv2d(64, 64, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2), \n",
    "    \n",
    "            nn.Conv2d(64, 64, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.AvgPool2d(2, 2), \n",
    "    \n",
    "            nn.Flatten(), \n",
    "            nn.Linear(65536 , 256),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256,128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 2),\n",
    "          \n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "name = \"ConvNet2\"\n",
    "model = to_device(Net2(), device)\n",
    "# model = model.cuda()\n",
    "history = [evaluate(model, val_loader)]\n",
    "num_epochs = 15\n",
    "opt_func = torch.optim.Adam\n",
    "lr = 4e-4\n",
    "history += fit(num_epochs, lr, model, train_loader, val_loader)\n",
    "histories[name] = history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "880a9f3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net3(BaseModule):\n",
    "    def __init__(self):\n",
    "        super(Net3, self).__init__()\n",
    "\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Conv2d(3, 32, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(),\n",
    "\n",
    "            nn.MaxPool2d(2, 2),\n",
    "\n",
    "            nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1), \n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "\n",
    "\n",
    "            nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2), \n",
    "    \n",
    "            nn.Conv2d(128, 128, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.AvgPool2d(2, 2), \n",
    "    \n",
    "            nn.Flatten(), \n",
    "            nn.Linear(65536 , 256),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256,128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 2),\n",
    "          \n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "    \n",
    "name = \"ConvNet3\"\n",
    "model = to_device(Net3(), device)\n",
    "# model = model.cuda()\n",
    "history = [evaluate(model, val_loader)]\n",
    "num_epochs = 15\n",
    "opt_func = torch.optim.Adam\n",
    "lr = 4e-4\n",
    "history += fit(num_epochs, lr, model, train_loader, val_loader)\n",
    "histories[name] = history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "76937fa2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<generator object Module.parameters at 0x000001E422E87120>\n"
     ]
    }
   ],
   "source": [
    "p = model.parameters()\n",
    "print(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e025616e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16904834\n"
     ]
    }
   ],
   "source": [
    "model = Net2()\n",
    "\n",
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print(count_parameters(model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cab0de6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "\n",
    "with open('convNets.json', 'w') as outfile:\n",
    "    json.dump(histories, outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1bf78f8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
